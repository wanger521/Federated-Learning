 # 第一章 简介
 * 人工智能的应用涉及：语音处理、图像处理、自然语言处理、人机博弈、自动驾驶和健康医疗等。
 * 分布式机器学习与其他分布式系统不同，需要考虑它对数据的鲁棒性，对算法精度的特别要求，以及泛化性
 
 #第二章 机器学习基础
 ## 模型类别
 * 从学习目标来看，分为回归分类排序问题
 * 从训练数据特征来看，有监督、半监督、无监督、弱监督学习
 * 从模型复杂度来看，分为线性和非线性模型
 * 从模型功能，氛围生成模型和判别模型
 
 ## 损失函数
 * 损失函数与误差函数有关，但具有更好的数学性质，例如连续 可导 凸性， 容易优化
 * 常见的分类损失函数
 ** Hinge损失函数：l(w;x,y)=max{0,1-yg(x;w)}
 ** 指数损失函数：l(w;x,y) = exp(-yg(x;w))
 ** 交叉熵损失函数：sigmoid给出二分类的概率，softmax给出多分类的概率，再定义交叉熵损失函数，l(w;x,y) = $-\sum_{z\in{-1,1}}I_{y=z}logP(Y=z|x;w)$
 最小化交叉熵损失函数等价于最大化预测函数g所对应的条件似然函数。
 
 ## 常用的机器学习模型
 * 线性模型
 * 核方法与支持向量机 通过核方法吧原始输入控件变换为一个高维空间，从而找到一个超平面，使得原分类问题线性可分，且间隔最大。
 * 决策树与boosting 生成树状结构的决策模型，boosting是集合模型
 * 神经网络 激活函数（sigmoid tanh ReLU）全连接神经网络在训练中，通常选取交叉熵损失函数，使用梯度下降法来求解模型参数
 包括 全连接网络、卷积神经网络、循环神经网络等
 
 ##理论
 * 我们希望泛化误差尽可能地小，这个包括优化误差、估计误差和近似误差
 
 # 第三章 分布式机器学习框架
 ## 概念
 * 分布式机器学习对应的三大情形：计算并行（多线程多机并行计算），训练数据并行（目前为止最常见，划分数据），模型训练并行（模型分开，对通信要求高）
 * 包含四大模块：数据与模型划分，单机优化，通信，数据与模型聚合
 
 ## 模型与数据划分
 * 训练样本划分：有放回的随机采样，置乱切分（无放回的随机采样）
 * 维度划分：不同节点不同维度，配合特定优化方法使用（例如坐标下降法）
 * 模型划分：需要考虑模型的结构特点，例如对于神经网络，可以横向逐层划分，也可以纵向跨层划分，或者每个节点存储骨干网络，其余数据进行分布式训练
 
 ## 单机优化模块
 * 最小化经验损失函数
 
 ## 通信
 * 迭代式mapreduce，基于参数服务器的通信拓扑，基于数据流的通信拓扑
 * 同步通信，异步通信，混合同步，半同步
 
 ## 数据与模型聚合
 * 模型平均，解一致性优化我呢提（如ADMM），还可以模型集成。凸问题可以保证精度，非凸很难。对于、nonidd问题，可以模型集成，就是会增大模型规模
 
 ## 总结
 * 理论性一般讨论收敛性，加速比，泛化性
 * 本书结构
 
 # 第四章 单机优化之确定性算法
